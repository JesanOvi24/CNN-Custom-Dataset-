{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c583d99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from skimage import io\n",
    "from skimage.transform import resize\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b98e6ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "508f9d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"dogcat\\\\cat.csv\")\n",
    "df2 = df.copy()\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa5948a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    id_value = row[\"id\"]\n",
    "    label_value = row[\"label\"]\n",
    "    id_value -= 1\n",
    "    id_str = str(id_value)\n",
    "    value = f\"cat.{id_str}.JPG\"\n",
    "    #print(value)\n",
    "    #print(label_value)\n",
    "    df[\"id\"] = value\n",
    "    df[\"label\"] = label_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f497006",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df2.iterrows():\n",
    "    id_value = row[\"id\"]\n",
    "    label_value = row[\"label\"]\n",
    "    id_value -= 1\n",
    "    id_str = str(id_value)\n",
    "    value = f\"dog.{id_str}.JPG\"\n",
    "    #print(value)\n",
    "    #print(label_value)\n",
    "    df2[\"id\"] = value\n",
    "    df2[\"label\"] = label_value+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dadf59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2080c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  id  label\n",
      "0      cat.12499.JPG      0\n",
      "1      cat.12499.JPG      0\n",
      "2      cat.12499.JPG      0\n",
      "3      cat.12499.JPG      0\n",
      "4      cat.12499.JPG      0\n",
      "...              ...    ...\n",
      "12495  dog.12499.JPG      1\n",
      "12496  dog.12499.JPG      1\n",
      "12497  dog.12499.JPG      1\n",
      "12498  dog.12499.JPG      1\n",
      "12499  dog.12499.JPG      1\n",
      "\n",
      "[25000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "result_df = pd.concat([df, df2], axis=0)\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d23a78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class catdogDataset(Dataset):\n",
    "    def __init__(self, annotation, rootdic, transform = None, target_size=(256, 256)):\n",
    "        self.annotation = annotation\n",
    "        self.rootdic = rootdic\n",
    "        self.transform = transform\n",
    "        self.target_size = target_size\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.annotation)\n",
    "    def __getitem__(self, index):\n",
    "        imgPath = os.path.join(self.rootdic, self.annotation.iloc[index, 0])\n",
    "        image = io.imread(imgPath)\n",
    "        image = resize(image, self.target_size, anti_aliasing=True) # convert the image into 256x256\n",
    "        \n",
    "        y = torch.tensor([float(self.annotation.iloc[index, 1])])\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return (image, y)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff0fd853",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = catdogDataset(annotation = result_df, rootdic = \"dogcat\\\\traindata\", transform = transforms.ToTensor(), target_size=(256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d9e9d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = torch.utils.data.random_split(dataset, [20000, 5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3bf622f",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channel = 3\n",
    "num_classes = 2\n",
    "batch_size = 32\n",
    "num_epochs = 5\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a4411b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset = train_set, batch_size = batch_size, shuffle = True)\n",
    "test_loader = DataLoader(dataset = test_set, batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c529a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 256, 256])\n",
      "torch.Size([32, 1])\n"
     ]
    }
   ],
   "source": [
    "for batch, (data, target) in enumerate(train_loader):\n",
    "    print(data.shape)\n",
    "    print(target.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75ddbce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.batch_norm1 = nn.BatchNorm2d(64)  # Add Batch Normalization\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.dropout1 = nn.Dropout(0.25)  # Add Dropout\n",
    "\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.batch_norm2 = nn.BatchNorm2d(128)  # Add Batch Normalization\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.dropout2 = nn.Dropout(0.25)  # Add Dropout\n",
    "\n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.batch_norm3 = nn.BatchNorm2d(256)  # Add Batch Normalization\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.dropout3 = nn.Dropout(0.25)  # Add Dropout\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(256 * (256 // 8) * (256 // 8), 512)\n",
    "        self.batch_norm4 = nn.BatchNorm1d(512)  # Add Batch Normalization\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.dropout4 = nn.Dropout(0.5)  # Add Dropout\n",
    "        self.fc2 = nn.Linear(512, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(self.dropout1(self.relu1(self.batch_norm1(self.conv1(x)))))\n",
    "        x = self.pool2(self.dropout2(self.relu2(self.batch_norm2(self.conv2(x)))))\n",
    "        x = self.pool3(self.dropout3(self.relu3(self.batch_norm3(self.conv3(x)))))\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(self.dropout4(self.relu4(self.batch_norm4(x))))\n",
    "        return x\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3f49fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleCNN(num_classes)  # Example model\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992a98a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8709778189659119\n",
      "0.008770090527832508\n",
      "0.014284297823905945\n",
      "0.01035232748836279\n",
      "0.02531273663043976\n",
      "0.013792121782898903\n",
      "0.01039901003241539\n",
      "0.014010470360517502\n",
      "0.008060258813202381\n",
      "0.009519131854176521\n",
      "0.007821165025234222\n",
      "0.017257990315556526\n",
      "0.005997910629957914\n",
      "0.005780461244285107\n",
      "0.01338915340602398\n",
      "0.00647020386531949\n",
      "0.005773739889264107\n",
      "0.005205187480896711\n",
      "0.006142358295619488\n",
      "0.008049591444432735\n",
      "0.005675383843481541\n",
      "0.00419302424415946\n",
      "0.004385827574878931\n",
      "0.004970822483301163\n",
      "0.004096026532351971\n",
      "0.007431075908243656\n",
      "0.004686540458351374\n",
      "0.009319777600467205\n",
      "0.0035257297568023205\n",
      "0.0053640250116586685\n",
      "0.03188356012105942\n",
      "0.0047114999033510685\n",
      "0.003110310761258006\n",
      "0.03097016178071499\n",
      "0.0046474686823785305\n",
      "0.006445405073463917\n",
      "0.0040879580192267895\n",
      "0.0070683155208826065\n",
      "0.0026093253400176764\n",
      "0.004416474141180515\n",
      "0.0035135233774781227\n",
      "0.002729118103161454\n",
      "0.002233682433143258\n",
      "0.002032893244177103\n",
      "0.0021710593719035387\n",
      "0.0017150412313640118\n",
      "0.0018809294560924172\n",
      "0.0038589895702898502\n",
      "0.0018597138114273548\n",
      "0.001897122012451291\n",
      "0.0016933210426941514\n",
      "0.0015614823205396533\n",
      "0.0015257655177265406\n",
      "0.001694127218797803\n",
      "0.0016867716331034899\n",
      "0.0014839760260656476\n",
      "0.001540105207823217\n",
      "0.001405610702931881\n",
      "0.0024801245890557766\n",
      "0.005300493910908699\n",
      "0.001317451591603458\n",
      "0.0013879085890948772\n",
      "0.0018246008548885584\n",
      "0.0035224435850977898\n",
      "0.001271790941245854\n",
      "0.00950576364994049\n",
      "0.001623313408344984\n",
      "0.002204864053055644\n",
      "0.00174317869823426\n",
      "0.0017538394313305616\n",
      "0.001268840627744794\n",
      "0.0012827629689127207\n",
      "0.0015844085719436407\n",
      "0.0020025395788252354\n",
      "0.0008571952348574996\n",
      "0.0010300528956577182\n",
      "0.0010138361249119043\n",
      "0.0008759848424233496\n",
      "0.0014337257016450167\n",
      "0.0016113381134346128\n",
      "0.0008828096324577928\n",
      "0.0011824097018688917\n",
      "0.0010192554909735918\n",
      "0.0013233463978394866\n",
      "0.000995148904621601\n",
      "0.0008468662854284048\n",
      "0.0008950118208304048\n",
      "0.0007864731596782804\n",
      "0.0011098298709839582\n",
      "0.002403722144663334\n",
      "0.0010293013183400035\n",
      "0.0012982977787032723\n",
      "0.0011653488036245108\n",
      "0.002708806423470378\n",
      "0.0013256758684292436\n",
      "0.0008585249306634068\n",
      "0.003041948890313506\n",
      "0.0014493244234472513\n",
      "0.0011177028063684702\n",
      "0.0007606762228533626\n",
      "0.004515929147601128\n",
      "0.002438361756503582\n",
      "0.003115441184490919\n",
      "0.0008254122803919017\n",
      "0.0020067389123141766\n",
      "0.0006892678793519735\n",
      "0.0005786950932815671\n",
      "0.001220301608555019\n",
      "0.000709280779119581\n",
      "0.0020593523513525724\n",
      "0.0013240415137261152\n",
      "0.0010568280704319477\n",
      "0.0005608192877843976\n",
      "0.0013914159499108791\n",
      "0.004476552829146385\n",
      "0.0006350880721583962\n",
      "0.0006526787183247507\n",
      "0.003663179697468877\n",
      "0.0006587597890757024\n",
      "0.0018314812332391739\n",
      "0.001802903600037098\n",
      "0.0013336489209905267\n",
      "0.0008215890266001225\n",
      "0.0005674019921571016\n",
      "0.0037092810962349176\n",
      "0.0007182614062912762\n",
      "0.0021885624155402184\n",
      "0.0009877175325527787\n",
      "0.0004542208043858409\n",
      "0.0005813364405184984\n",
      "0.0012060487642884254\n",
      "0.0007340802112594247\n",
      "0.0009706415003165603\n",
      "0.0021316525526344776\n",
      "0.000667705899104476\n",
      "0.0014755699085071683\n",
      "0.0005404966650530696\n",
      "0.0014824280515313148\n",
      "0.0007311719236895442\n",
      "0.00041857550968416035\n",
      "0.0008025045390240848\n",
      "0.004685195628553629\n",
      "0.0005203909822739661\n",
      "0.000914594333153218\n",
      "0.0003773692296817899\n",
      "0.0005904888384975493\n",
      "0.0010647529270499945\n",
      "0.0012245469260960817\n",
      "0.0004560663946904242\n",
      "0.0003881179727613926\n",
      "0.0010996521450579166\n",
      "0.0005649776430800557\n",
      "0.00034446289646439254\n",
      "0.00045302172657102346\n",
      "0.0004897193284705281\n",
      "0.001082350267097354\n",
      "0.0004009003168903291\n",
      "0.00038547764415852726\n",
      "0.00047464814269915223\n",
      "0.00036306740366853774\n",
      "0.0003712114703375846\n",
      "0.00033329735742881894\n",
      "0.00028258858947083354\n",
      "0.00051635573618114\n",
      "0.00027042775764130056\n",
      "0.0007415126892738044\n",
      "0.0005337325856089592\n",
      "0.001804484287276864\n",
      "0.0003278693766333163\n",
      "0.0003715383354574442\n",
      "0.000768945668824017\n",
      "0.00044408810208551586\n",
      "0.00024580516037531197\n",
      "0.003075422951951623\n",
      "0.00042815523920580745\n",
      "0.00040710114990361035\n",
      "0.001019690535031259\n",
      "0.00024756102357059717\n",
      "0.0003545020008459687\n",
      "0.0011156138498336077\n",
      "0.0005373620078898966\n",
      "0.00041884349775500596\n",
      "0.0004250300407875329\n",
      "0.0003191630821675062\n",
      "0.00046361162094399333\n",
      "0.0003724706475622952\n",
      "0.0016051859129220247\n",
      "0.0007319513242691755\n",
      "0.00029451516456902027\n",
      "0.0002624601766001433\n",
      "0.00025948917027562857\n",
      "0.0003396429819986224\n",
      "0.00028061307966709137\n",
      "0.0002817451022565365\n",
      "0.0002783839590847492\n",
      "0.00025345254107378423\n",
      "0.0003226661356166005\n",
      "0.00038677608245052397\n",
      "0.0004943388630636036\n",
      "0.00024479071726091206\n",
      "0.001306861056946218\n",
      "0.0006097343866713345\n",
      "0.00026636014808900654\n",
      "0.0009063826873898506\n",
      "0.0005366227123886347\n",
      "0.0005238568410277367\n",
      "0.00024367363948840648\n",
      "0.0002510062186047435\n",
      "0.00027489702915772796\n",
      "0.00035038054920732975\n",
      "0.00021238172485027462\n",
      "0.00027581313042901456\n",
      "0.0002730096457526088\n",
      "0.00021370695321820676\n",
      "0.0007851155241951346\n",
      "0.0005836770869791508\n",
      "0.0002566926123108715\n",
      "0.00022396168787963688\n",
      "0.00026893996982835233\n",
      "0.00032499199733138084\n",
      "0.00031584640964865685\n",
      "0.00035516906064003706\n",
      "0.002622546860948205\n",
      "0.0008749965345486999\n",
      "0.000520843721460551\n",
      "0.0008079966646619141\n",
      "0.0014152702642604709\n",
      "0.00027982910978607833\n",
      "0.0002113381342496723\n",
      "0.0002998763811774552\n",
      "0.0002356183686060831\n",
      "0.0002240802423330024\n",
      "0.000868951203301549\n",
      "0.00022589896980207413\n",
      "0.0002299131010659039\n",
      "0.0016439987812191248\n",
      "0.0009223039960488677\n",
      "0.0002225234202342108\n",
      "0.00013076880713924766\n",
      "0.00019958270422648638\n",
      "0.00016095871978905052\n",
      "0.002525263000279665\n",
      "0.00025088590336963534\n",
      "0.0011755814775824547\n",
      "0.000247503980062902\n",
      "0.00024339379160664976\n",
      "0.0005060612456873059\n",
      "0.0006418230477720499\n",
      "0.0009393373620696366\n",
      "0.00016690196935087442\n",
      "0.0006601196364499629\n",
      "0.000197329354705289\n",
      "0.00036113359965384007\n",
      "0.006196755915880203\n",
      "0.00021110317902639508\n",
      "0.00016082296497188509\n",
      "0.00018547996296547353\n",
      "0.0002208521036664024\n",
      "0.0004089544527232647\n",
      "0.0001615192595636472\n",
      "0.0008443620754405856\n",
      "0.0001865388621808961\n",
      "0.00016989769937936217\n",
      "0.00038945686537772417\n",
      "0.0008495606016367674\n",
      "0.00031275584478862584\n",
      "0.00017442481475882232\n",
      "0.00015775093925185502\n",
      "0.0033432208001613617\n",
      "0.00012504207552410662\n",
      "0.0003002980083692819\n",
      "0.0002085620362777263\n",
      "0.00012205063831061125\n",
      "0.00047647126484662294\n",
      "0.00024641022901050746\n",
      "0.0003666360571514815\n",
      "0.0011898849625140429\n",
      "0.00013065554958302528\n",
      "0.00010622715490171686\n",
      "0.0010703111765906215\n",
      "0.0014541147975251079\n",
      "0.00015942688332870603\n",
      "0.000702932826243341\n",
      "0.0003485887427814305\n",
      "0.00011753432772820815\n",
      "0.00010468806431163102\n",
      "0.00016109232092276216\n",
      "0.00012823435827158391\n",
      "0.00015225708193611354\n",
      "0.0007643920835107565\n",
      "0.00014234776608645916\n",
      "0.0002775590110104531\n",
      "0.00011084131256211549\n",
      "0.00041886806138791144\n",
      "0.00021482219744939357\n",
      "0.00012110803072573617\n",
      "0.0007849985267966986\n",
      "0.00010126794222742319\n",
      "0.0005337752518244088\n",
      "0.00027173079433850944\n",
      "0.00010685488086892292\n",
      "0.00012168016110081226\n",
      "0.000274537451332435\n",
      "0.00013768488133791834\n",
      "0.00012813176726922393\n",
      "0.0001042995136231184\n",
      "0.00030505325412377715\n",
      "0.00010317334090359509\n",
      "0.00016966767725534737\n",
      "0.0006861862493678927\n",
      "0.00011212419485673308\n",
      "0.00020340786431916058\n",
      "0.0004288056225050241\n",
      "9.400122507940978e-05\n",
      "0.00011066999286413193\n",
      "0.0001216535601997748\n",
      "0.00014467693108599633\n",
      "0.0003794051008298993\n",
      "0.00012061913002980873\n",
      "0.0003531824622768909\n",
      "0.00012819573748856783\n",
      "0.00020286643120925874\n",
      "0.0005650144885294139\n",
      "0.001189902308396995\n",
      "0.00011573410301934928\n",
      "0.000789603334851563\n",
      "0.00030128739308565855\n",
      "0.0008796387701295316\n",
      "8.8924789451994e-05\n",
      "0.00039808498695492744\n",
      "0.00019881021580658853\n",
      "0.0003177562030032277\n",
      "0.00014174832904245704\n",
      "8.819779031910002e-05\n",
      "0.0006577985477633774\n",
      "0.0005075201625004411\n",
      "0.0006519457092508674\n",
      "0.00010494137677596882\n",
      "9.436090476810932e-05\n",
      "0.00014150296919979155\n",
      "0.0001078447894542478\n",
      "8.227904618252069e-05\n",
      "0.0003613800508901477\n",
      "8.193557005142793e-05\n",
      "0.003045170335099101\n",
      "9.855371172307059e-05\n",
      "0.002468913095071912\n",
      "0.00024130212841555476\n",
      "0.00017165186000056565\n",
      "0.0014867517165839672\n",
      "5.286371742840856e-05\n",
      "0.0001261054421775043\n",
      "7.861678022891283e-05\n",
      "0.00018777564400807023\n",
      "0.00013271448551677167\n",
      "5.8505978813627735e-05\n",
      "6.649202259723097e-05\n",
      "8.790523861534894e-05\n",
      "0.00027431308990344405\n",
      "9.830413182498887e-05\n",
      "0.00017191415827255696\n",
      "0.00047980991075746715\n",
      "0.0008458177326247096\n",
      "7.966324483277276e-05\n",
      "0.00015141481708269566\n",
      "0.00012057862477377057\n",
      "9.7029929747805e-05\n",
      "0.00032699014991521835\n",
      "5.8230569266015664e-05\n",
      "0.00015431059000547975\n",
      "8.766358223510906e-05\n",
      "0.00010372432734584436\n",
      "6.412436050595716e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.950868580839597e-05\n",
      "9.157492604572326e-05\n",
      "0.0001891893334686756\n",
      "9.565804793965071e-05\n",
      "9.915627015288919e-05\n",
      "0.00014570998609997332\n",
      "6.658942584181204e-05\n",
      "0.0002972251095343381\n",
      "8.159857679856941e-05\n",
      "0.00011883881961693987\n",
      "0.00017703569028526545\n",
      "0.0003933293919544667\n",
      "0.00039343145908787847\n",
      "6.211626168806106e-05\n",
      "6.4127663790714e-05\n",
      "0.000120506614621263\n",
      "0.0013529497664421797\n",
      "5.1727285608649254e-05\n",
      "5.9929727285634726e-05\n",
      "0.00013082163059152663\n",
      "0.0002659310703165829\n",
      "0.00017594758537597954\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        # Convert input data to the desired data type\n",
    "        images = images.to(torch.float32)\n",
    "        labels = labels.to(torch.float32) \n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        print(loss.item())\n",
    "         #print(outputs)\n",
    "        #print(labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Print the loss after each epoch\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Optionally, evaluate the model on the test set after training\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        # Convert input data to the desired data type\n",
    "        images = images.to(torch.float32)\n",
    "        labels = labels.to(torch.float32) \n",
    "\n",
    "        # Forward pass and evaluation logic\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Calculate and print any evaluation metric (e.g., accuracy)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        accuracy = (predicted == labels).sum().item() / labels.size(0)\n",
    "        print(f\"Accuracy on the test set: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a4f3b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG16 = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M']\n",
    "# Linear layer 4096x4096x1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c01b1593",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG_net(nn.Module):\n",
    "    def __init__(self, in_channels = 3, num_classes = 1000):\n",
    "        super(VGG_net, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.conv_layers = self.create_conv_layers(VGG16)\n",
    "        \n",
    "        self.fcs = nn.Sequential(\n",
    "            nn.Linear(512*7*7, 4096), # image shape is 224x224 and 5 time Maxpooling so 224/2^5 = 7\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(4096, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fcs(x)\n",
    "        return x\n",
    "    \n",
    "    def create_conv_layers(self, arc):\n",
    "        layers = []\n",
    "        in_channels = self.in_channels\n",
    "        \n",
    "        for x in arc:\n",
    "            if type(x) == int:\n",
    "                out_channels = x\n",
    "                layers += [nn.Conv2d(in_channels = in_channels, out_channels = out_channels,\n",
    "                                    kernel_size = (3,3), stride = (1,1), padding = (1,1)), nn.BatchNorm2d(x), nn.ReLU()]\n",
    "                in_channels = x\n",
    "                \n",
    "            elif x == 'M':\n",
    "                layers += [nn.MaxPool2d(kernel_size = (2,2), stride = (2,2))]\n",
    "                \n",
    "        return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d6a07c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG_net(in_channels = 3, num_classes = 1000).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "28ba629c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1000])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1, 3, 224, 224).to(device)\n",
    "print(model(x).shape)\n",
    "# Input image must have shape 224x224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bfb8b345",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b6853e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
